{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from collections import OrderedDict as od\n",
    "import pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Company</th>\n",
       "      <th>Price</th>\n",
       "      <th>% Change</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ARVL</td>\n",
       "      <td>Arrival</td>\n",
       "      <td>$7.76</td>\n",
       "      <td>5.86%</td>\n",
       "      <td>695.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AVCT</td>\n",
       "      <td>American Virtual Cloud</td>\n",
       "      <td>$1.30</td>\n",
       "      <td>6.55%</td>\n",
       "      <td>447.68K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFRI</td>\n",
       "      <td>Biofrontera</td>\n",
       "      <td>$6.02</td>\n",
       "      <td>9.45%</td>\n",
       "      <td>117.64K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BORR</td>\n",
       "      <td>Borr Drilling</td>\n",
       "      <td>$1.65</td>\n",
       "      <td>7.84%</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BQ</td>\n",
       "      <td>Boqii Holding</td>\n",
       "      <td>$1.20</td>\n",
       "      <td>5.26%</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CFV</td>\n",
       "      <td>CF Acquisition Corp V</td>\n",
       "      <td>$10.57</td>\n",
       "      <td>6.87%</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFVI</td>\n",
       "      <td>CF Acquisition</td>\n",
       "      <td>$12.54</td>\n",
       "      <td>11.36%</td>\n",
       "      <td>249.02K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBP</td>\n",
       "      <td>Corbus Pharmaceuticals</td>\n",
       "      <td>$0.73</td>\n",
       "      <td>5.79%</td>\n",
       "      <td>25.66K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ESSC</td>\n",
       "      <td>East Stone Acquisition</td>\n",
       "      <td>$14.41</td>\n",
       "      <td>6.74%</td>\n",
       "      <td>39.08K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRTX</td>\n",
       "      <td>Galera Therapeutics</td>\n",
       "      <td>$3.14</td>\n",
       "      <td>16.29%</td>\n",
       "      <td>1.46M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IMTX</td>\n",
       "      <td>Immatics</td>\n",
       "      <td>$12.39</td>\n",
       "      <td>5.26%</td>\n",
       "      <td>3219.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INPX</td>\n",
       "      <td>Inpixon</td>\n",
       "      <td>$0.73</td>\n",
       "      <td>8.93%</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IPWR</td>\n",
       "      <td>Ideal Power</td>\n",
       "      <td>$11.34</td>\n",
       "      <td>13.40%</td>\n",
       "      <td>4422.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LICY</td>\n",
       "      <td>Li-Cycle Holdings</td>\n",
       "      <td>$11.57</td>\n",
       "      <td>6.63%</td>\n",
       "      <td>8890.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESO</td>\n",
       "      <td>Mesoblast</td>\n",
       "      <td>$4.59</td>\n",
       "      <td>10.07%</td>\n",
       "      <td>1671.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NILE</td>\n",
       "      <td>BitNile Holdings</td>\n",
       "      <td>$1.61</td>\n",
       "      <td>5.92%</td>\n",
       "      <td>11.53K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEAC</td>\n",
       "      <td>SeaChange International</td>\n",
       "      <td>$1.71</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>2.39M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOUR</td>\n",
       "      <td>Tuniu</td>\n",
       "      <td>$1.03</td>\n",
       "      <td>6.69%</td>\n",
       "      <td>186.94K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UXIN</td>\n",
       "      <td>Uxin</td>\n",
       "      <td>$1.84</td>\n",
       "      <td>9.52%</td>\n",
       "      <td>175.79K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>YANG</td>\n",
       "      <td>Direxion Daily FTSE China Bear 3x Shares</td>\n",
       "      <td>$20.37</td>\n",
       "      <td>6.48%</td>\n",
       "      <td>6115.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stock                                   Company   Price % Change   Volume\n",
       "16  ARVL                                   Arrival   $7.76    5.86%   695.00\n",
       "13  AVCT                    American Virtual Cloud   $1.30    6.55%  447.68K\n",
       "6   BFRI                               Biofrontera   $6.02    9.45%  117.64K\n",
       "8   BORR                             Borr Drilling   $1.65    7.84%   577.00\n",
       "18    BQ                             Boqii Holding   $1.20    5.26%   300.00\n",
       "9    CFV                     CF Acquisition Corp V  $10.57    6.87%   150.00\n",
       "3   CFVI                            CF Acquisition  $12.54   11.36%  249.02K\n",
       "17  CRBP                    Corbus Pharmaceuticals   $0.73    5.79%   25.66K\n",
       "10  ESSC                    East Stone Acquisition  $14.41    6.74%   39.08K\n",
       "0   GRTX                       Galera Therapeutics   $3.14   16.29%    1.46M\n",
       "19  IMTX                                  Immatics  $12.39    5.26%  3219.00\n",
       "7   INPX                                   Inpixon   $0.73    8.93%   120.00\n",
       "1   IPWR                               Ideal Power  $11.34   13.40%  4422.00\n",
       "12  LICY                         Li-Cycle Holdings  $11.57    6.63%  8890.00\n",
       "4   MESO                                 Mesoblast   $4.59   10.07%  1671.00\n",
       "15  NILE                          BitNile Holdings   $1.61    5.92%   11.53K\n",
       "2   SEAC                   SeaChange International   $1.71   13.24%    2.39M\n",
       "11  TOUR                                     Tuniu   $1.03    6.69%  186.94K\n",
       "5   UXIN                                      Uxin   $1.84    9.52%  175.79K\n",
       "14  YANG  Direxion Daily FTSE China Bear 3x Shares  $20.37    6.48%  6115.00"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url = \"https://www.benzinga.com/movers\"\n",
    "url = \"https://www.benzinga.com/premarket/\"\n",
    "tables = pd.read_html(url)\n",
    "#df = tables[0]\n",
    "df = tables[5]\n",
    "#df.sort_values['Stock']\n",
    "#stock = df['Stock'].tolist()\n",
    "sdf1 = df.sort_values('Stock')\n",
    "sdf1.\n",
    "#val = sdf1[[0, '% Change']]\n",
    "#val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20832/2365742799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Stock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'% Change'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Stock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'% Change'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Stock'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#df_all['% Diff'] = df_all['% Change_x'] - df_all['% Change_y']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'% Diff'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'% Change_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(self, periods)\u001b[0m\n\u001b[0;32m   2646\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \"\"\"\n\u001b[1;32m-> 2648\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         return self._constructor(result, index=self.index).__finalize__(\n\u001b[0;32m   2650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"diff\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(arr, n, axis, stacklevel)\u001b[0m\n\u001b[0;32m   1709\u001b[0m         \u001b[0mlag_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_lag_indexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1711\u001b[1;33m         \u001b[0mout_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres_indexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres_indexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlag_indexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_timedelta\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "#url = \"https://www.benzinga.com/movers\"\n",
    "url = \"https://www.benzinga.com/premarket/\"\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "#df = tables[0]\n",
    "df = tables[5]\n",
    "#df.sort_values['Stock']\n",
    "#stock = df['Stock'].tolist()\n",
    "#https://stackoverflow.com/questions/17095101/compare-two-dataframes-and-output-their-differences-side-by-side\n",
    "sdf2 = df.sort_values('Stock')\n",
    "df_all = pd.concat([sdf1[[\"Stock\", \"% Change\"]].set_index('Stock'), sdf2[[\"Stock\", \"% Change\"]].set_index('Stock')], \n",
    "                   axis='columns', keys=['First', 'Second'])\n",
    "#df_all['% Diff'] = df_all['First'] - df_all['Second']\n",
    "df_all = pd.merge(sdf1[['Stock', '% Change']], sdf2[['Stock', '% Change']], how='left', on='Stock')\n",
    "#df_all['% Diff'] = df_all['% Change_x'] - df_all['% Change_y']\n",
    "df_all['% Diff'] = df_all['% Change_y'].diff()\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 800  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_func(df1, df2, uid, dedupe=True, labels=('df1', 'df2'), drop=[]):\n",
    "    dict_df = {labels[0]: df1, labels[1]: df2}\n",
    "    col1 = df1.columns.values.tolist()\n",
    "    col2 = df2.columns.values.tolist()\n",
    "\n",
    "    # There could be columns known to be different, hence allow user to pass this as a list to be dropped.\n",
    "    if drop:\n",
    "        print ('Ignoring columns {} in comparison.'.format(', '.join(drop)))\n",
    "        col1 = list(filter(lambda x: x not in drop, col1))\n",
    "        col2 = list(filter(lambda x: x not in drop, col2))\n",
    "        df1 = df1[col1]\n",
    "        df2 = df2[col2]\n",
    "\n",
    "\n",
    "    # Step 1 - Check if no. of columns are the same:\n",
    "    len_lr = len(col1), len(col2)\n",
    "    assert len_lr[0]==len_lr[1], \\\n",
    "    'Cannot compare frames with different number of columns: {}.'.format(len_lr)\n",
    "\n",
    "    # Step 2a - Check if the set of column headers are the same\n",
    "    #           (order doesnt matter)\n",
    "    assert set(col1)==set(col2), \\\n",
    "    'Left column headers are different from right column headers.' \\\n",
    "       +'\\n   Left orphans: {}'.format(list(set(col1)-set(col2))) \\\n",
    "       +'\\n   Right orphans: {}'.format(list(set(col2)-set(col1)))\n",
    "\n",
    "    # Step 2b - Check if the column headers are in the same order\n",
    "    if col1 != col2:\n",
    "        print ('[Note] Reordering right Dataframe...')\n",
    "        df2 = df2[col1]\n",
    "\n",
    "    # Step 3 - Check datatype are the same [Order is important]\n",
    "    if set((df1.dtypes == df2.dtypes).tolist()) - {True}:\n",
    "        print ('dtypes are not the same.')\n",
    "        df_dtypes = pd.DataFrame({labels[0]:df1.dtypes,labels[1]:df2.dtypes,'Diff':(df1.dtypes == df2.dtypes)})\n",
    "        df_dtypes = df_dtypes[df_dtypes['Diff']==False][[labels[0],labels[1],'Diff']]\n",
    "        print (df_dtypes)\n",
    "    else:\n",
    "        print ('DataType check: Passed')\n",
    "\n",
    "    # Step 4 - Check for duplicate rows\n",
    "    if dedupe:\n",
    "        for key, df in dict_df.items():\n",
    "            if df.shape[0] != df.drop_duplicates().shape[0]:\n",
    "                print(key + ': Duplicates exists, they will be dropped.')\n",
    "                dict_df[key] = df.drop_duplicates()\n",
    "\n",
    "    # Step 5 - Check for duplicate uids.\n",
    "    if type(uid)==str or type(uid)==list:\n",
    "        print ('Uniqueness check: {}'.format(uid))\n",
    "        for key, df in dict_df.items():\n",
    "            count_uid = df.shape[0]\n",
    "            count_uid_unique = df[uid].drop_duplicates().shape[0]\n",
    "            var = [0,1][count_uid_unique == df.shape[0]] #<-- Round off to the nearest integer if it is 100%\n",
    "            pct = round(100*count_uid_unique/df.shape[0], var)\n",
    "            print ('{}: {} out of {} are unique ({}%).'.format(key, count_uid_unique, count_uid, pct))\n",
    "\n",
    "    # Checks complete, begin merge. '''Remenber to dedupe, provide labels for common_no_match'''\n",
    "    dict_result = od()\n",
    "    df_merge = pd.merge(df1, df2, on=col1, how='inner')\n",
    "    if not df_merge.shape[0]:\n",
    "        print ('Error: Merged DataFrame is empty.')\n",
    "    else:\n",
    "        dict_result[labels[0]] = df1\n",
    "        dict_result[labels[1]] = df2\n",
    "        dict_result['Merge'] = df_merge\n",
    "        if type(uid)==str:\n",
    "            uid = [uid]\n",
    "\n",
    "        if type(uid)==list:\n",
    "            df1_only = df1.append(df_merge).reset_index(drop=True)\n",
    "            df1_only['Duplicated']=df1_only.duplicated(keep=False)  #keep=False, marks all duplicates as True\n",
    "            df1_only = df1_only[df1_only['Duplicated']==False]\n",
    "            df2_only = df2.append(df_merge).reset_index(drop=True)\n",
    "            df2_only['Duplicated']=df2_only.duplicated(keep=False)\n",
    "            df2_only = df2_only[df2_only['Duplicated']==False]\n",
    "\n",
    "            label = labels[0]+' or '+labels[1]\n",
    "            df_lc = df1_only.copy()\n",
    "            df_lc[label] = labels[0]\n",
    "            df_rc = df2_only.copy()\n",
    "            df_rc[label] = labels[1]\n",
    "            df_c = df_lc.append(df_rc).reset_index(drop=True)\n",
    "            df_c['Duplicated'] = df_c.duplicated(subset=uid, keep=False)\n",
    "            df_c1 = df_c[df_c['Duplicated']==True]\n",
    "            df_c1 = df_c1.drop('Duplicated', axis=1)\n",
    "            df_uc = df_c[df_c['Duplicated']==False]\n",
    "\n",
    "            df_uc_left = df_uc[df_uc[label]==labels[0]]\n",
    "            df_uc_right = df_uc[df_uc[label]==labels[1]]\n",
    "\n",
    "            dict_result[labels[0]+'_only'] = df_uc_left.drop(['Duplicated', label], axis=1)\n",
    "            dict_result[labels[1]+'_only'] = df_uc_right.drop(['Duplicated', label], axis=1)\n",
    "            dict_result['Diff'] = df_c1.sort_values(uid).reset_index(drop=True)\n",
    "\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataType check: Passed\n",
      "Uniqueness check: Fruits\n",
      "df1: 3 out of 3 are unique (100.0%).\n",
      "df2: 3 out of 3 are unique (100.0%).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mango', 'durian']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([['apple', '1'], ['banana', 2], ['coconut',3]], columns=['Fruits','Quantity'])\n",
    "df2 = pd.DataFrame([['apple', '1'], ['mango', 3], ['durian',4]], columns=['Fruits','Quantity'])\n",
    "#df2 = pd.DataFrame([['apple', '1'], ['banana', 3], ['durian',4]], columns=['Fruits','Quantity'])\n",
    "dict1 = diff_func(df1, df2, 'Fruits')\n",
    "#dict1['df2_only']\n",
    "dfholder = dict1['df2_only']\n",
    "dfholder\n",
    "fruit = dfholder['Fruits'].tolist()\n",
    "fruit\n",
    "#bool(dict1['df2_only'].empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "\n",
    "#voice_num = 2\n",
    "text = fruit\n",
    "\n",
    "#voices = engine.getProperty('voices')\n",
    "#engine.setProperty('voice', voices[voice_num].id)\n",
    "\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9555b9be6a8a13f87de7d1b7fbfd783e15351004eb1db55b677e0d8b308b3dfd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
